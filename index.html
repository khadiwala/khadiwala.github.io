<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>Ramblesaurus</title>
    <meta name="description" content="">
    <meta name="author" content="Ravi Khadiwala">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
    <script src="http://khadiwala.github.io/theme/html5.js"></script>
    <![endif]-->

    <!-- Le styles -->
    <link href="http://khadiwala.github.io/theme/bootstrap.min.css" rel="stylesheet">
    <link href="http://khadiwala.github.io/theme/bootstrap.min.responsive.css" rel="stylesheet">
    <link href="http://khadiwala.github.io/theme/local.css" rel="stylesheet">
    <link href="http://khadiwala.github.io/theme/pygments.css" rel="stylesheet">

	<script type="text/x-mathjax-config">
	  MathJax.Hub.Config({
	  "HTML-CSS": {
	  styles: {
	  ".MathJax .mo, .MathJax .mi": {color: "black ! important"}}
	  },
	  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']],processEscapes: true}
	  });
	  MathJax.Hub.Register.StartupHook("HTML-CSS Jax Ready",function () {
	  var VARIANT = MathJax.OutputJax["HTML-CSS"].FONTDATA.VARIANT;
	  VARIANT["normal"].fonts.unshift("MathJax_SansSerif");
	  VARIANT["bold"].fonts.unshift("MathJax_SansSerif-bold");
	  VARIANT["italic"].fonts.unshift("MathJax_SansSerif-italic");
	  VARIANT["-tex-mathit"].fonts.unshift("MathJax_SansSerif-italic");
	  });
	  MathJax.Hub.Register.StartupHook("SVG Jax Ready",function () {
	  var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;
	  VARIANT["normal"].fonts.unshift("MathJax_SansSerif");
	  VARIANT["bold"].fonts.unshift("MathJax_SansSerif-bold");
	  VARIANT["italic"].fonts.unshift("MathJax_SansSerif-italic");
	  VARIANT["-tex-mathit"].fonts.unshift("MathJax_SansSerif-italic");
	  });
	</script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>

</head>

<body>

<div class="navbar">
    <div class="navbar-inner">
    <div class="container">

         <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
             <span class="icon-bar"></span>
             <span class="icon-bar"></span>
             <span class="icon-bar"></span>
         </a>

        <a class="brand" href="http://khadiwala.github.io">Ramblesaurus</a>

        <div class="nav-collapse">
        <ul class="nav">
                    
                            <li><a href="http://khadiwala.github.io/pages/about.html">About</a></li>
                        </ul>
        </div>
        
    </div>
    </div>
</div>

<div class="container">
    <div class="content">
    <div class="row">

        <div class="span9">
                

<link rel="stylesheet" href="/theme/ipython.css">
        


    <div class='article'>
        <div class="content-title">
            <a href="http://khadiwala.github.io/thats-what-she-said.html"><h1>That's What She Said</h1></a>
            Fri 17 May 2013

by <a class="url fn" href="http://khadiwala.github.io/author/ravi-khadiwala.html">Ravi Khadiwala</a>
 


 
        </div>
        
        <div><div class="ipynb"><div class="text_cell_render border-box-sizing rendered_html">
<h1 class="ipynb">That's What She Said:</h1>
<h1 class="ipynb">Automated Detection of Innuendos</h1>
<p>Here I describe my second pass at writing a classifier that can detect sentences that are likely to contain sexual inuendos. Both implementations can be found on <a href="https://github.com/mrgrieves/ThatsWhatSheSaid/tree/sk-twss">github</a>, as well as this ipython notebook (you'll need the data folder to use this notebook), which is by far the most interesting way to read this post. Although this is pretty much a joke project, since I wrote the original project I've really grown to like the <a href="http://scikit-learn.org/stable/">scikit-learn</a> library, as opposed to using the basic classifiers in nltk. I got substantially better performance and memory usage, and used a cool feature extraction technique that is well suited to bag of words models. Also I learned the wonder that is blogging with ipython notebooks, which is just too cool. Skip to the bottom to see some examples of the classifier in action, or try the old version here <a href="http://twssd.heroku.com">here</a>.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h1 class="ipynb">Data</h1>
<p>The data folder of the github project contains three sources. Two are of negative instances: one scraped from fmylife and the other from texts from last night. The thought here is that these samples would be written a similar tone and style to twss instances without being twss worthy. The positive samples are scraped from twssStories.com. The punctuation has already been processed out, and the data has been slightly cleaned. This <a href="http://blog.echen.me/2011/05/05/twss-building-a-thats-what-she-said-classifier/">data</a> (also availiable in my repo) was scraped by Edwin Chen, and the approach seems to be from this <a href="http://www.aclweb.org/anthology-new/P/P11/P11-2016.pdf">paper</a></p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">chain</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">load</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span>  <span class="p">:</span> <span class="nb">open</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>
<span class="n">stopwords</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;english&quot;</span><span class="p">))</span>
<span class="n">stopwords</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&quot;twss&quot;</span><span class="p">)</span>
<span class="n">stopwords</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&quot;fml&quot;</span><span class="p">)</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s">&quot;data/twss-stories-parsed.txt&quot;</span><span class="p">)</span>
<span class="n">negs</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;data/fmylife-parsed.txt&quot;</span><span class="p">,</span><span class="s">&quot;data/texts-from-last-night-parsed.txt&quot;</span><span class="p">]</span>
<span class="n">neg</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="nb">map</span><span class="p">(</span><span class="n">load</span><span class="p">,</span><span class="n">negs</span><span class="p">)))</span>

<span class="k">def</span> <span class="nf">tokens</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">s</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="p">]</span>

<span class="n">pos_f</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">pos</span><span class="p">)</span>
<span class="n">neg_f</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">neg</span><span class="p">)</span>
<span class="n">instances</span> <span class="o">=</span> <span class="n">chain</span><span class="p">(</span><span class="n">pos_f</span><span class="p">,</span><span class="n">neg_f</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pos</span><span class="p">)),</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">neg</span><span class="p">))])</span>
</pre></div>

</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h1 class="ipynb">Feature Extraction</h1>
<h2 class="ipynb">Hash Trick</h2>
<p>Here's the more interesting part. This uses the fairly recent FeatureHasher functionality in SciKit-Learn starting with version 0.13.</p>
<p>With any text classification that has a decent size corpus, we can expect to see a huge number of features. However, each instance has very few of these features active. The first way to mitigate this effect is to use a <a href="http://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix">sparse matrix</a> as representation of the feature vectors. The additional benefit that the <a href="http://scikit-learn.org/stable/modules/feature_extraction.html#feature-hashing">hash trick</a> provides is that the hash maps directly to the indicies in the array. This means we don't have to keep an in memory mapping to feature indicies. </p>
<p>I had previously implemented this using a more straightforward approach and paid pretty large memory costs, that bottlenecked the entire process. Add to that I had not discovered the beauty of ipython notebooks and their mechanism modularizing code and only running certain cells, and I had a very slow development cycle. That's the implementation in the master branch of my twss repo. </p>
<h2 class="ipynb">Negatives</h2>
<p>You can't go backwords from the hashes to the features, so you lose the ability to easily introspect about the performance of features in the classifier. Because of this, I pulled out some info on the most informative features from when I did this experiment with nltk's implementation of naive bayes; see the end of this post (because dirty words are funny). Since this was mostly to try out different models and an interesting feature extraction technique, I did not go through the pain of mapping every single feature to it's index to find which features corresponded to the indicies that were most informative in the classifiers I tried out.</p>
<p>Potential collisions grow more likely as you approach the size of the hash space, $2^{31}$, (which I clearly do not with this data set). They are slightly mitigated by using a signed hash that determines the sign of the feature. This means collisions are more likely to cancel out than accumulate bias. It was suggested in <a href="http://alex.smola.org/papers/2009/Weinbergeretal09.pdf">Weinberger et al</a></p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">feature_extraction</span> <span class="k">as</span> <span class="n">fe</span>
<span class="n">fh</span> <span class="o">=</span> <span class="n">fe</span><span class="o">.</span><span class="n">FeatureHasher</span><span class="p">(</span><span class="n">input_type</span><span class="o">=</span><span class="s">&#39;string&#39;</span><span class="p">)</span>
<span class="n">hashed_instances</span> <span class="o">=</span> <span class="n">fh</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">instances</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h1 class="ipynb">Classification</h1>
<h2 class="ipynb">Benchmarking</h2>
<p>I pulled and modified some code to do the evaluation and timing (as well as the plotting further down), from the very good example from scikit <a href="http://scikit-learn.org/0.13/auto_examples/document_classification_20newsgroups.html">Classification of Text Documents using Sparse Features</a>. </p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>


<span class="k">def</span> <span class="nf">benchmark</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">):</span>
    <span class="n">clf_descr</span> <span class="o">=</span> <span class="n">clf</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">print</span><span class="p">(</span><span class="mi">80</span> <span class="o">*</span> <span class="s">&#39;_&#39;</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">&quot;Training &quot;</span><span class="p">,</span> <span class="n">clf_descr</span><span class="p">)</span>
    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">Y</span><span class="p">[</span><span class="n">train</span><span class="p">])</span>
    <span class="n">train_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span>

    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">test</span><span class="p">])</span>
    <span class="n">test_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span>

    <span class="n">score</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="n">test</span><span class="p">],</span> <span class="n">pred</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">&quot;f1-score:   </span><span class="si">%0.3f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">score</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s">&quot;confusion matrix:&quot;</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="n">test</span><span class="p">],</span> <span class="n">pred</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">clf_descr</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">train_time</span><span class="p">,</span> <span class="n">test_time</span>
</pre></div>

</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h2 class="ipynb">Models</h2>
<p>Scikit-learn is so well designed that swapping models in and out is too easy not to try. I looked for anything I could apply to a sparse matrix with negative entities. </p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Perceptron</span><span class="p">,</span> <span class="n">SGDClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVC</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">NearestCentroid</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">cross_validation</span>

<span class="n">cv</span> <span class="o">=</span> <span class="n">cross_validation</span><span class="o">.</span><span class="n">KFold</span><span class="p">(</span><span class="n">hashed_instances</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">n_folds</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">train</span><span class="p">,</span><span class="n">test</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">cv</span><span class="p">))</span> <span class="c"># just use one of the folds</span>

<span class="n">clss</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="s">&quot;Perceptron&quot;</span><span class="p">,</span> <span class="n">Perceptron</span><span class="p">(</span><span class="n">n_iter</span><span class="o">=</span><span class="mi">50</span><span class="p">)),</span>
        <span class="p">(</span><span class="s">&quot;NearestCentroid&quot;</span><span class="p">,</span> <span class="n">NearestCentroid</span><span class="p">()),</span>
        <span class="p">(</span><span class="s">&quot;LinearSVC l1&quot;</span><span class="p">,</span> <span class="n">LinearSVC</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">&#39;l2&#39;</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s">&quot;l1&quot;</span><span class="p">,</span> <span class="n">dual</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)),</span>
        <span class="p">(</span><span class="s">&quot;LinearSVC l2&quot;</span><span class="p">,</span> <span class="n">LinearSVC</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">&#39;l2&#39;</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s">&quot;l2&quot;</span><span class="p">,</span> <span class="n">dual</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)),</span>
        <span class="p">(</span><span class="s">&quot;SGD l1&quot;</span><span class="p">,</span> <span class="n">SGDClassifier</span><span class="p">(</span><span class="n">alpha</span><span class="o">=.</span><span class="mo">0001</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s">&quot;l1&quot;</span><span class="p">)),</span>
        <span class="p">(</span><span class="s">&quot;SGD l2&quot;</span><span class="p">,</span> <span class="n">SGDClassifier</span><span class="p">(</span><span class="n">alpha</span><span class="o">=.</span><span class="mo">0001</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s">&quot;l2&quot;</span><span class="p">)),</span>
        <span class="p">(</span><span class="s">&quot;SGD elasticnet&quot;</span><span class="p">,</span> <span class="n">SGDClassifier</span><span class="p">(</span><span class="n">alpha</span><span class="o">=.</span><span class="mo">0001</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s">&quot;elasticnet&quot;</span><span class="p">))</span>
       <span class="p">]</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">[</span><span class="n">benchmark</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span><span class="n">hashed_instances</span><span class="p">,</span><span class="n">target</span><span class="p">,</span><span class="n">train</span><span class="p">,</span><span class="n">test</span><span class="p">)</span> <span class="k">for</span> <span class="n">cls</span> <span class="ow">in</span> <span class="n">clss</span><span class="p">]</span>
</pre></div>

</div>
</div>
<div class="vbox output_wrapper">
<div class="output vbox">
<div class="hbox output_area">
<div class="prompt output_prompt"></div>
<div class="output_subarea output_stream output_stdout">
<pre class="ipynb">________________________________________________________________________________
Training  Perceptron
f1-score:   0.864
confusion matrix:
[[1108   56]
 [  56  357]]
________________________________________________________________________________
Training  NearestCentroid
f1-score:   0.682
confusion matrix:
[[1001  163]
 [ 115  298]]
________________________________________________________________________________
Training  LinearSVC l1
f1-score:   0.861
confusion matrix:
[[1109   55]
 [  59  354]]
________________________________________________________________________________
Training  LinearSVC l2
f1-score:   0.885
confusion matrix:
[[1117   47]
 [  48  365]]
________________________________________________________________________________
Training  SGD l1
f1-score:   0.851
confusion matrix:
[[1111   53]
 [  68  345]]
________________________________________________________________________________
Training  SGD l2
f1-score:   0.874
confusion matrix:
[[1117   47]
 [  56  357]]
________________________________________________________________________________
Training  SGD elasticnet
f1-score:   0.847
confusion matrix:
[[1111   53]
 [  71  342]]

confusion matrix:
[[1108   56]
 [  56  357]]
________________________________________________________________________________
Training  NearestCentroid
f1-score:   0.682
confusion matrix:
[[1001  163]
 [ 115  298]]
________________________________________________________________________________
Training  LinearSVC l1
f1-score:   0.861
confusion matrix:
[[1109   55]
 [  59  354]]
________________________________________________________________________________
Training  LinearSVC l2
f1-score:   0.885
confusion matrix:
[[1117   47]
 [  48  365]]
________________________________________________________________________________
Training  SGD l1
f1-score:   0.851
confusion matrix:
[[1111   53]
 [  68  345]]
________________________________________________________________________________
Training  SGD l2
f1-score:   0.874
confusion matrix:
[[1117   47]
 [  56  357]]
________________________________________________________________________________
Training  SGD elasticnet
f1-score:   0.847
confusion matrix:
[[1111   53]
 [  71  342]]
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[45]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="kn">import</span> <span class="nn">pylab</span> <span class="kn">as</span> <span class="nn">pl</span>

<span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">))</span>

<span class="n">collected</span> <span class="o">=</span> <span class="p">[[</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">results</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)]</span>

<span class="n">clf_names</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">training_time</span><span class="p">,</span> <span class="n">test_time</span> <span class="o">=</span> <span class="n">collected</span>
<span class="n">training_time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">training_time</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">training_time</span><span class="p">)</span>
<span class="n">test_time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_time</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">test_time</span><span class="p">)</span>

<span class="n">pl</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">&quot;Score&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figsize</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="o">.</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">&quot;score&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">&#39;r&#39;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">indices</span> <span class="o">+</span> <span class="o">.</span><span class="mi">3</span><span class="p">,</span> <span class="n">training_time</span><span class="p">,</span> <span class="o">.</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">&quot;training time&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">&#39;g&#39;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">indices</span> <span class="o">+</span> <span class="o">.</span><span class="mi">6</span><span class="p">,</span> <span class="n">test_time</span><span class="p">,</span> <span class="o">.</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">&quot;test time&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">&#39;b&#39;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">yticks</span><span class="p">(())</span>
<span class="n">pl</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">&#39;lower left&#39;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">.</span><span class="mi">5</span><span class="p">))</span>
<span class="n">pl</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=.</span><span class="mi">25</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">clf_names</span><span class="p">):</span>
    <span class="n">pl</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="o">-.</span><span class="mi">1</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
</pre></div>

</div>
</div>
<div class="vbox output_wrapper">
<div class="output vbox">
<div class="hbox output_area">
<div class="prompt output_prompt"></div>
<div class="output_subarea output_display_data">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAx4AAAGPCAYAAADSnwbxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"></img>
</div>
</div>
</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h1 class="ipynb">That's What She Said!</h1>
<p>Great! Most of the models had similar performance, but on this data set it looks like LinearSVC performed well. Let's use this classifier to make crude jokes!</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[46]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="kn">import</span> <span class="nn">re</span>

<span class="k">def</span> <span class="nf">to_sentences</span><span class="p">(</span><span class="n">document</span><span class="p">):</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s">&quot;&quot;</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">load</span><span class="p">(</span><span class="n">document</span><span class="p">):</span>
        <span class="n">text</span> <span class="o">+=</span> <span class="n">line</span>
    <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&quot;\.|\?|\!&quot;</span><span class="p">,</span><span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">LinearSVC</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">&#39;l2&#39;</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s">&quot;l1&quot;</span><span class="p">,</span> <span class="n">dual</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">hashed_instances</span><span class="p">,</span><span class="n">target</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_twss</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
    <span class="n">sentences</span> <span class="o">=</span> <span class="n">to_sentences</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
    <span class="n">hashed</span> <span class="o">=</span> <span class="n">fh</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span><span class="n">sentences</span><span class="p">))</span>
    <span class="n">twss_pairs</span> <span class="o">=</span> <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">zip</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">hashed</span><span class="p">)))</span>
    <span class="k">return</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">twss_pairs</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h2 class="ipynb">State of the Union</h2>
<p>First let's try Obama's 2013 State of the Union. Shouldn't expect too much from here, as most of these sentences will probably be non personal and contain policy related language. </p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[47]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">get_twss</span><span class="p">(</span><span class="s">&quot;data/2013-state-of-union.txt&quot;</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
</pre></div>

</div>
</div>
<div class="vbox output_wrapper">
<div class="output vbox">
<div class="hbox output_area">
<div class="prompt output_prompt"></div>
<div class="output_subarea output_stream output_stdout">
<pre class="ipynb">our housing market is healing, our stock market is rebounding, and consumers, patients, and homeowners enjoy stronger protections than ever before
but we gather here knowing that there are millions of americans whose hard work and dedication have not yet been rewarded
it is our unfinished task to restore the basic bargain that built this country  the idea that if you work hard and meet your responsibilities, you can get ahead, no matter where you come from, what you look like, or who you love
now, some in this congress have proposed preventing only the defense cuts by making even bigger cuts to things like education and job training; medicare and social security benefits
our government shouldnt make promises we cannot keep  but we must keep the promises weve already made
the politics will be hard for both sides
its not a bigger government we need, but a smarter government that sets priorities and invests in broad-based growth
there are things we can do, right now, to accelerate this trend
we produce more natural gas than ever before  and nearly everyones energy bill is lower because of it
last year, wind energy added nearly half of all new power capacity in america
solar energy gets cheaper by the year  so lets drive costs down even further
as long as countries like china keep going all-in on clean energy, so must we
if a non-partisan coalition of ceos and retired generals and admirals can get behind this idea, then so can we
americas energy sector is just one part of an aging infrastructure badly in need of repair
and i know that you want these job-creating projects in your districts
now, even with better high schools, most young people will need some higher education
tonight, lets also recognize that there are communities in this country where no matter how hard you work, its virtually impossible to get ahead
lets offer incentives to companies that hire americans whove got what it takes to fill that job opening, but have been out of work so long that no one will give them a chance
stronger families
stronger communities
i recognize that in our democracy, no one should just take my word that were doing things the right way
overwhelming majorities of americans  americans who believe in the 2nd amendment  have come together around commonsense reform  like background checks that will make it harder for criminals to get their hands on a gun
police chiefs are asking our help to get weapons of war and massive ammunition magazines off our streets, because they are tired of being outgunned
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Hah! most of these are bad and it's not hard to see why they were misclassified, a lot of use of comparitive adjectives like bigger, harder further, etc. There are a couple good ones though, I enjoyed:</p>
<ul>
<li>
<p>the politics will be hard for both sides</p>
</li>
<li>
<p>we produce more natural gas than ever before  and nearly everyones energy bill is lower because of it</p>
</li>
<li>
<p>there are things we can do, right now, to accelerate this trend</p>
</li>
</ul>
<p>It's a long speech with 217 sentences - if we say that none of these are good examples of that's what she said instances, this classifier was correct 197 times out of 200 (.9078). This is around the accuracy we saw on the test set (and I think some of these positive examples are correct classifications).</p>
<p>Let's see if there is anything better in George Bush's 2002 state of the union. If I remember correctly we could broach some sensitive topics, hot dog!</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[48]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">get_twss</span><span class="p">(</span><span class="s">&quot;data/2002-state-of-union.txt&quot;</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
</pre></div>

</div>
</div>
<div class="vbox output_wrapper">
<div class="output vbox">
<div class="hbox output_area">
<div class="prompt output_prompt"></div>
<div class="output_subarea output_stream output_stdout">
<pre class="ipynb">yet the state of our union has never been stronger
i don&apos;t want to play football until i can play with you again some day
so long as training camps operate, so long as nations harbor terrorists, freedom is at risk
our war on terror is well begun, but it is only begun
this campaign may not be finished on our watch  yet it must be and it will be waged on our watch
we can&apos;t stop short
last year, some in this hall thought my tax relief plan was too small; some thought it was too big
employees who have worked hard and saved all their lives should not have to risk losing everything if their company fails
for too long our culture has said, &quot;if it feels good, do it
we&apos;ve come to know truths that we will never question: evil is real, and it must be opposed
deep in the american character, there is honor, and it is stronger than cynicism
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Bahaha! Almost all of these are good twss candidates, or so far from it that it's pretty great. </p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h1 class="ipynb">I Just Blue Myself</h1>
<p>Lets try some positive examples: namely some awkward quotes from Arrested Development's Tobias Funke.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[49]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="n">all_examples</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">to_sentences</span><span class="p">(</span><span class="s">&quot;data/tobias.txt&quot;</span><span class="p">))</span>
<span class="n">positive</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">get_twss</span><span class="p">(</span><span class="s">&quot;data/tobias.txt&quot;</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;twss&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">all_examples</span> <span class="o">&amp;</span> <span class="n">positive</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\n</span><span class="s">negative&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">all_examples</span> <span class="o">-</span> <span class="n">positive</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
</pre></div>

</div>
</div>
<div class="vbox output_wrapper">
<div class="output vbox">
<div class="hbox output_area">
<div class="prompt output_prompt"></div>
<div class="output_subarea output_stream output_stdout">
<pre class="ipynb">twss
ooh, i can taste those meaty, leading man parts in my mouth
even if it means me taking a chubby, i will suck it up

negative
i just blue myself
i&apos;m afraid i prematurely shot my wad on what was supposed to be a dry run if you will, so i&apos;m afraid i have something of a mess on my hands
i wouldn&apos;t mind kissing that man between the cheeks
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>2 out 5 ain't terrible - I thought "I just blue myself" was a shot in the dark. Anyways the goal of these types of classifiers are to maximize preciscion rather than recall. You can easily pump many documents/examples through it, it's just important that the ones that do get positivley classified are correct. Lets try a couple more positive ones. In the spirit of "The Office" series finale, how about Michael Scott that's what she said quotes. I've grabbed a few of the top ones from <a href="http://www.reddit.com/r/DunderMifflin/comments/17zz4c/hey_guys_what_is_your_favorite_michael_scott/">this</a> reddit post, (Spoilers: and the one from the finale!)</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[50]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="n">all_examples</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">to_sentences</span><span class="p">(</span><span class="s">&quot;data/office.txt&quot;</span><span class="p">))</span>
<span class="n">positive</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">get_twss</span><span class="p">(</span><span class="s">&quot;data/office.txt&quot;</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;twss&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">all_examples</span> <span class="o">&amp;</span> <span class="n">positive</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\n</span><span class="s">negative&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">all_examples</span> <span class="o">-</span> <span class="n">positive</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
</pre></div>

</div>
</div>
<div class="vbox output_wrapper">
<div class="output vbox">
<div class="hbox output_area">
<div class="prompt output_prompt"></div>
<div class="output_subarea output_stream output_stdout">
<pre class="ipynb">twss
wow, that is really hard
well, you always left me satisfied and smiling
my mother is coming
michael, you came
you really think you can go all day long

negative
and was she under you the whole time

no, i need two men on this
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Not bad at all, 5/7 correctly identified. The first three positives are the ones that Jim softballs to Michael when he's trying get him to say it, awesome that the classifier got all of those. </p>
<p>That's about it! </p>
<p>Now, I believe I promised some dirty words ...</p>
<pre class="ipynb"><code>    contains(bigger) = True                1 : 0      =     97.0 : 1.0
      contains(suck) = True                1 : 0      =     57.1 : 1.0
     contains(shove) = True                1 : 0      =     48.9 : 1.0
   contains(sucking) = True                1 : 0      =     36.0 : 1.0
     contains(found) = True                0 : 1      =     35.3 : 1.0
       contains(wow) = True                1 : 0      =     34.5 : 1.0
    contains(sticky) = True                1 : 0      =     34.2 : 1.0
     contains(gotta) = True                1 : 0      =     32.3 : 1.0
     contains(tight) = True                1 : 0      =     29.4 : 1.0
      contains(hole) = True                1 : 0      =     29.0 : 1.0
       contains(wet) = True                1 : 0      =     27.9 : 1.0
      contains(damn) = True                1 : 0      =     26.8 : 1.0
     contains(quick) = True                1 : 0      =     24.9 : 1.0
     contains(worry) = True                1 : 0      =     24.9 : 1.0
      contains(hard) = True                1 : 0      =     24.0 : 1.0
     contains(youll) = True                1 : 0      =     22.7 : 1.0
      contains(push) = True                1 : 0      =     22.6 : 1.0
     contains(feels) = True                1 : 0      =     21.6 : 1.0
 contains(boyfriend) = True                0 : 1      =     21.6 : 1.0
    contains(harder) = True                1 : 0      =     20.4 : 1.0
      contains(year) = True                0 : 1      =     20.1 : 1.0
  contains(bathroom) = True                0 : 1      =     20.1 : 1.0
    contains(longer) = True                1 : 0      =     19.4 : 1.0
  contains(slippery) = True                1 : 0      =     19.4 : 1.0
   contains(decided) = True                0 : 1      =     19.1 : 1.0
      contains(meat) = True                1 : 0      =     18.3 : 1.0
    contains(inches) = True                1 : 0      =     17.8 : 1.0
    contains(called) = True                0 : 1      =     17.7 : 1.0
     contains(comes) = True                1 : 0      =     17.5 : 1.0
      contains(slow) = True                1 : 0      =     17.2 : 1.0
    contains(faster) = True                1 : 0      =     17.2 : 1.0
      contains(easy) = True                1 : 0      =     16.1 : 1.0
     contains(holes) = True                1 : 0      =     16.1 : 1.0
      contains(fast) = True                1 : 0      =     15.9 : 1.0
     contains(stick) = True                1 : 0      =     15.8 : 1.0
       contains(sex) = True                0 : 1      =     15.8 : 1.0
   contains(replies) = True                1 : 0      =     15.7 : 1.0
     contains(juicy) = True                1 : 0      =     15.7 : 1.0
     contains(taste) = True                1 : 0      =     15.4 : 1.0
      contains(ones) = True                1 : 0      =     15.4 : 1.0
       contains(big) = True                1 : 0      =     15.1 : 1.0
      contains(pull) = True                1 : 0      =     15.1 : 1.0
      contains(boss) = True                0 : 1      =     14.6 : 1.0
     contains(hurts) = True                1 : 0      =     14.5 : 1.0
       contains(fit) = True                1 : 0      =     14.2 : 1.0
      contains(gave) = True                0 : 1      =     14.1 : 1.0
      contains(fits) = True                1 : 0      =     13.9 : 1.0
     contains(white) = True                1 : 0      =     13.4 : 1.0
    contains(easier) = True                1 : 0      =     13.1 : 1.0
        contains(oh) = True                1 : 0      =     13.0 : 1.0
     contains(mouth) = True                1 : 0      =     13.0 : 1.0
     contains(tired) = True                1 : 0      =     12.7 : 1.0
      contains(lick) = True                1 : 0      =     12.7 : 1.0
      contains(wide) = True                1 : 0      =     12.7 : 1.0
     contains(years) = True                0 : 1      =     12.6 : 1.0
     contains(stuff) = True                1 : 0      =     12.2 : 1.0
   contains(replied) = True                1 : 0      =     12.1 : 1.0
       contains(aww) = True                1 : 0      =     12.0 : 1.0
     contains(honey) = True                1 : 0      =     12.0 : 1.0
      contains(wrap) = True                1 : 0      =     12.0 : 1.0
     contains(stiff) = True                1 : 0      =     12.0 : 1.0
   contains(shaking) = True                1 : 0      =     12.0 : 1.0
       contains(pop) = True                1 : 0      =     12.0 : 1.0
      contains(itll) = True                1 : 0      =     11.8 : 1.0
      contains(soft) = True                1 : 0      =     11.6 : 1.0
       contains(new) = True                0 : 1      =     11.6 : 1.0
     contains(slide) = True                1 : 0      =     11.5 : 1.0
      contains(door) = True                0 : 1      =     11.5 : 1.0
       contains(bar) = True                0 : 1      =     11.4 : 1.0
   contains(blowing) = True                1 : 0      =     11.4 : 1.0
      contains(home) = True                0 : 1      =     10.7 : 1.0
   contains(stretch) = True                1 : 0      =     10.5 : 1.0
       contains(cat) = True                0 : 1      =     10.5 : 1.0
      contains(shes) = True                0 : 1      =     10.5 : 1.0
    contains(window) = True                0 : 1      =     10.2 : 1.0
     contains(screw) = True                1 : 0      =     10.2 : 1.0
     contains(moist) = True                1 : 0      =     10.2 : 1.0
       contains(bet) = True                1 : 0      =     10.2 : 1.0
      contains(inch) = True                1 : 0      =     10.2 : 1.0
 contains(swallowed) = True                1 : 0      =     10.2 : 1.0
      contains(oral) = True                1 : 0      =     10.2 : 1.0
   contains(shoving) = True                1 : 0      =     10.2 : 1.0
      contains(lean) = True                1 : 0      =     10.2 : 1.0
  contains(dripping) = True                1 : 0      =     10.2 : 1.0
   contains(alright) = True                1 : 0      =     10.2 : 1.0
      contains(bend) = True                1 : 0      =     10.2 : 1.0
     contains(drunk) = True                0 : 1      =     10.0 : 1.0
       contains(omg) = True                1 : 0      =      9.8 : 1.0
contains(girlfriend) = True                0 : 1      =      9.5 : 1.0
    contains(mother) = True                0 : 1      =      9.3 : 1.0
       contains(dog) = True                0 : 1      =      9.2 : 1.0
   contains(careful) = True                1 : 0      =      9.1 : 1.0
      contains(call) = True                0 : 1      =      9.0 : 1.0
    contains(eating) = True                0 : 1      =      9.0 : 1.0
     contains(wanna) = True                1 : 0      =      8.9 : 1.0
     contains(balls) = True                1 : 0      =      8.8 : 1.0
    contains(bought) = True                0 : 1      =      8.8 : 1.0
        contains(ex) = True                0 : 1      =      8.8 : 1.0
    contains(throat) = True                1 : 0      =      8.7 : 1.0
</code></pre>
<p>This is the ranked list of the 100 most informative features when I did this experiment with naieve bayes. The first column is the feature, the second column the ratio of positives to negatives or negatives to positive with that feature present.</p>
<p>And with that, all possible remnants of humor left in the That's What She Said jokes have been taken out behind the shed and shot.</p>
</div></div></div>
        <hr />
    </div>
		
    
 
        

 

    <div class='article'>
        <a href="http://khadiwala.github.io/rubiks-cube-solver-in-go.html"><h2>"Rubiks Cube Solver in Go"</h2></a>
        <div class= "well small"> Thu 28 March 2013

by <a class="url fn" href="http://khadiwala.github.io/author/ravi-khadiwala.html">Ravi Khadiwala</a>
 


 </div>
        <div class="summary"><h2>Shut up about go already</h2>
<p>Despite being a few years after its initial release, I can't stop hearing about Go. 
I decided to rework a simple enough algorithm I understood to learn basic Go syntax, and see how it performs in the memory and speed departments. 
I implemented Thistlethwaite ...</p> <a class="btn btn-info xsmall" href="http://khadiwala.github.io/rubiks-cube-solver-in-go.html">read more</a></div>
    </div>	
				
    
 
        

 

    <div class='article'>
        <a href="http://khadiwala.github.io/Twitter based Event Detection and Analysis System.html"><h2>"TEDAS"</h2></a>
        <div class= "well small"> Sat 16 March 2013

by <a class="url fn" href="http://khadiwala.github.io/author/ravi-khadiwala.html">Ravi Khadiwala</a>
 


 </div>
        <div class="summary"><h2>Twitter based Event Detection and Analysis System</h2>
<hr />
<p>Twitter is a distributed, fast, and localized system for spreading information. It's also noisy, inaccurate, and completly disorganized. 
Discovery tweets that are related to important events, for example crimes and natural disasters, and providing georgraphical context could be a useful way to ...</p> <a class="btn btn-info xsmall" href="http://khadiwala.github.io/Twitter based Event Detection and Analysis System.html">read more</a></div>
    </div>	
				
            <div class="pagination">
<ul>
    <li class="prev disabled"><a href="#">&larr; Previous</a></li>

    <li class="active"><a href="http://khadiwala.github.io/index.html">1</a></li>

    <li class="next disabled"><a href="#">&rarr; Next</a></li>

</ul>
</div>    
 
  
        </div>
        
        <div class="span3">

            <div class="well" style="padding: 8px 0; background-color: #FBFBFB;">
            <ul class="nav nav-list">
                <li class="nav-header"> 
                Site
                </li>
            
                <li><a href="http://khadiwala.github.io/">Archives</a>
                <li><a href="http://khadiwala.github.io/tags.html">Tags</a>
                <li><a href="http://khadiwala.github.io/" rel="alternate">Atom feed</a></li>
                            </ul>
            </div>


                        <div class="well" style="padding: 8px 0; background-color: #FBFBFB;">
            <ul class="nav nav-list">
                <li class="nav-header"> 
                Categories
                </li>
                
                                <li><a href="http://khadiwala.github.io/category/ai.html">AI</a></li>
                                <li><a href="http://khadiwala.github.io/category/misc.html">misc</a></li>
                                   
            </ul>
            </div>
            

            

                        <div class="social">
            <div class="well" style="padding: 8px 0; background-color: #FBFBFB;">
            <ul class="nav nav-list">
                <li class="nav-header"> 
                Social
                </li>
           
                                <li><a href="http://khadiwala.github.io">github</a></li>
                            </ul>
            </div>
            </div>
            
        </div>  
    </div>     </div> 
<footer>
<br />
<p><a href="http://khadiwala.github.io">Ramblesaurus</a> &copy; Ravi Khadiwala 2012</p>
</footer>

</div> <!-- /container -->
<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
<script src="http://twitter.github.com/bootstrap/assets/js/bootstrap-collapse.js"></script>
<script>var _gaq=[['_setAccount','UA-39357717-1'],['_trackPageview']];(function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];g.src='//www.google-analytics.com/ga.js';s.parentNode.insertBefore(g,s)}(document,'script'))</script>
 
</body>
</html>